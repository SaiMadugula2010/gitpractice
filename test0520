import boto3
import os
import os.path
from dotenv import load_dotenv

# Load AWS credentials
load_dotenv()

aws_access_key = os.getenv('AWS_ACCESS_KEY_ID')
aws_secret_key = os.getenv('AWS_SECRET_ACCESS_KEY')
aws_session_token = os.getenv('AWS_SESSION_TOKEN')  # Optional
aws_region = os.getenv('AWS_REGION', 'us-east-1')

# S3 bucket and folder prefix
bucket_name = 'sai'
prefix = 'test/'

# Local directory to save files (flat)
download_dir = 's3_downloads'
os.makedirs(download_dir, exist_ok=True)

# Initialize S3 client
s3 = boto3.client(
    's3',
    aws_access_key_id=aws_access_key,
    aws_secret_access_key=aws_secret_key,
    aws_session_token=aws_session_token,
    region_name=aws_region
)

print(f"Downloading files from s3://{bucket_name}/{prefix} to ./{download_dir}/")

# List all objects under prefix
paginator = s3.get_paginator('list_objects_v2')
for page in paginator.paginate(Bucket=bucket_name, Prefix=prefix):
    if 'Contents' not in page:
        continue
    for obj in page['Contents']:
        key = obj['Key']
        if key.endswith('/'):
            continue  # skip folder placeholders

        # Extract just the file name
        file_name = os.path.basename(key)
        local_path = os.path.join(download_dir, file_name)

        # If a file with the same name exists, add a suffix to avoid overwriting
        base, ext = os.path.splitext(file_name)
        counter = 1
        while os.path.exists(local_path):
            local_path = os.path.join(download_dir, f"{base}_{counter}{ext}")
            counter += 1

        try:
            print(f"Downloading {key} -> {local_path}")
            s3.download_file(bucket_name, key, local_path)
        except Exception as e:
            print(f"Error downloading {key}: {e}")
