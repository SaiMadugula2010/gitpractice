##############################################################################################
### Author: Byju Sudhakaran
### Date Started: 4/18/2022
### Last Update Date: 06/22/2023
### Lambda Function Name: mfdc_sdros_file_arrive
### Language: Python 3.9
##############################################################################################

import json
import re
import uuid
import boto3
import datetime
from datetime import datetime
import os
import logging
import io
import zipfile

#######################################################################
### Global Variables: Set the logger
#######################################################################
logger = logging.getLogger('mfdc_sdros_loader')
formatter = logging.Formatter('[%(levelname)s] %(message)s')
stream_handler = logging.StreamHandler()
stream_handler.setFormatter(formatter)
logger.addHandler(stream_handler)
logger.propagate = False
log_level_default = os.environ.get("LOG_LEVEL", "DEBUG")
function_name = ""

s3_client = boto3.client('s3')

##############################################################################################
### S3 Event triggers this Lambda Function when a file is dropped in the Raw S3 bucket.
##############################################################################################
def lambda_handler(event, context): 
    try:
        logger.setLevel(log_level_default)
        logger.debug(f"Event received : {event}")

        function_name = context.function_name

        # Get environment variables
        config_table = verify_and_get_dict_value(function_name, os.environ, 'config_table_name', True)
        app_name = verify_and_get_dict_value(function_name, os.environ, 'app_name', True)

        # Get config entries from DynamoDB
        config_values = setup_config_values_from_dynamoDB(config_table, app_name)

        # Extract bucket and file details
        config_values['file_bucket'] = event['Records'][0]['s3']['bucket']['name']
        config_values['file_key'] = event['Records'][0]['s3']['object']['key']
        key_parts = config_values['file_key'].split('/')
        config_values['file_name'] = key_parts[-1]

        logger.debug(f"Processing file {config_values['file_name']}")

        # Extract SDRID, asset class, and date from file name
        regExCompiled = re.compile(config_values['file_name_regex'])
        matchGroups = regExCompiled.search(config_values['file_name'])
        if matchGroups:
            config_values["file_dt"] = matchGroups.group('file_dt')
            config_values['sdr_id'] = matchGroups.group('sdr_id').upper()
            config_values['asset_class'] = matchGroups.group('asset_class').upper()
            config_values['file_group'] = f"SDROS_{config_values['asset_class'].upper()}"
        else:
            raise Exception(f"Cannot extract SDR ID, date, or asset class from file name: {config_values['file_name']}")

        # Update archive path to include "harmonized/os/<SDR_ID>/"
        config_values["archive_key"] = f"{config_values['bucket_info']['archive_key_prefix']}harmonized/os/{config_values['sdr_id']}/{config_values['file_name']}"

        # Initialize config values for file audit
        setup_config_values_for_FileAudit(config_values)

        # Build step function input
        sf_input = build_sf_input(config_values)
        logger.debug(f"Step function input: {sf_input}")

        # Call state machine
        call_state_machine(config_values, sf_input, config_values['file_name'])

    except ValueError as err:
        logger.error(f"ValueError in {function_name}: {str(err)}")
        raise err
    except Exception as ex:
        logger.error(f"Exception in {function_name}: {str(ex)}")
        raise ex

########################################################################################################################
### Function: Get Config values from DynamoDB table
########################################################################################################################
def setup_config_values_from_dynamoDB(config_table, app_name):
    logger.debug(f"Reading from DynamoDB: config_table - {config_table} app_name - {app_name}")

    dynamoDB = boto3.resource('dynamodb', region_name='us-east-1')
    table = dynamoDB.Table(config_table)
    response_payload = table.get_item(Key={'application_name': app_name})

    logger.debug(f"Response from DynamoDB: {response_payload}")
    config_values = response_payload.get('Item', {})
    config_values['app_name'] = app_name

    return config_values

########################################################################################################################
### Function: Initialize configuration for file audit
########################################################################################################################
def setup_config_values_for_FileAudit(config_values):
    file_audit = {
        "file_path": f"{config_values['file_bucket']}/{config_values['file_key'].rsplit('/', 1)[0]}",
        "file_name": config_values['file_key'].rsplit('/', 1)[-1],
        "process_step": "STAGE",
        "data_stream": "SDR",
        "sub_data_stream": f"{config_values['sdr_id']}_{config_values['asset_class']}",
        "action": "insert",
        "loader": "SDR 2.0"
    }

    log_parms = {"file_audit": file_audit}
    config_values["LogParams"] = log_parms
    config_values['ParentFileId'] = getAuditId(config_values["LogParams"])

    return config_values

########################################################################################################################
### Function: Get Audit ID from another Lambda
########################################################################################################################
def getAuditId(fileAuditConfig):
    logger.debug(f"FileAuditConfig: {fileAuditConfig}")

    lambda_client = boto3.client('lambda')
    response = lambda_client.invoke(
        FunctionName='mfdc_file_audit',
        InvocationType='RequestResponse',
        Payload=json.dumps(fileAuditConfig)
    )

    response_payload = json.loads(response["Payload"].read().decode("utf-8"))
    return response_payload.get("file_id", "")

########################################################################################################################
### Function: Build step function input JSON
########################################################################################################################
def build_sf_input(config_values):
    logger.debug(f"Building step function input for: {config_values['file_name']}")

    sf_values = {
        "SourceBucket": config_values['file_bucket'],
        "SourceKey": config_values['file_key'],
        "ArchiveBucket": config_values["bucket_info"]["archive_bucket"],
        "ArchiveKey": config_values["archive_key"],  # Updated path with harmonized/os/SDR_ID/
        "LogLevel": config_values['log'].get("log_level").upper(),
        "FileName": config_values['file_name'],
        "LogParams": config_values["LogParams"]
    }

    return sf_values

########################################################################################################################
### Function: Call the Step Function
########################################################################################################################
def call_state_machine(config_values, sm_input, file_name):
    stepFun_client = boto3.client("stepfunctions")
    sm_name = file_name.replace('.', '_') + "_" + datetime.now().strftime("%H_%M_%S")

    response = stepFun_client.start_execution(
        stateMachineArn=config_values["step_functions"]["loader_arn"],
        name=sm_name,
        input=json.dumps(sm_input)
    )

    logger.debug(f"State Machine Response: {response}")
    return response

########################################################################################################################
### Function: Retrieve a value from a dictionary with error handling
########################################################################################################################
def verify_and_get_dict_value(function_name, dict_of_values, data_key, is_required_field):
    if data_key in dict_of_values and dict_of_values[data_key]:
        return dict_of_values[data_key]

    if is_required_field:
        raise ValueError(f"Key {data_key} not found in {function_name}")

    return ""
